{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(Path('Resources/2019loans.csv'))\n",
    "test_df = pd.read_csv(Path('Resources/2020Q1loans.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for training data\n",
    "train_X = train_df.drop('loan_status', axis=1)\n",
    "train_X = train_X.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "train_y = LabelEncoder().fit_transform(train_df['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert categorical data to numeric and separate target feature for testing data\n",
    "test_X = test_df.drop('loan_status', axis=1)\n",
    "test_X = test_X.apply(LabelEncoder().fit_transform)\n",
    "\n",
    "test_y = LabelEncoder().fit_transform(test_df['loan_status'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unnamed: 0\n",
      "index\n",
      "loan_amnt\n",
      "int_rate\n",
      "installment\n",
      "home_ownership\n",
      "annual_inc\n",
      "verification_status\n",
      "pymnt_plan\n",
      "dti\n",
      "delinq_2yrs\n",
      "inq_last_6mths\n",
      "open_acc\n",
      "pub_rec\n",
      "revol_bal\n",
      "total_acc\n",
      "initial_list_status\n",
      "out_prncp\n",
      "out_prncp_inv\n",
      "total_pymnt\n",
      "total_pymnt_inv\n",
      "total_rec_prncp\n",
      "total_rec_int\n",
      "total_rec_late_fee\n",
      "recoveries\n",
      "collection_recovery_fee\n",
      "last_pymnt_amnt\n",
      "collections_12_mths_ex_med\n",
      "policy_code\n",
      "application_type\n",
      "acc_now_delinq\n",
      "tot_coll_amt\n",
      "tot_cur_bal\n",
      "open_acc_6m\n",
      "open_act_il\n",
      "open_il_12m\n",
      "open_il_24m\n",
      "mths_since_rcnt_il\n",
      "total_bal_il\n",
      "il_util\n",
      "open_rv_12m\n",
      "open_rv_24m\n",
      "max_bal_bc\n",
      "all_util\n",
      "total_rev_hi_lim\n",
      "inq_fi\n",
      "total_cu_tl\n",
      "inq_last_12m\n",
      "acc_open_past_24mths\n",
      "avg_cur_bal\n",
      "bc_open_to_buy\n",
      "bc_util\n",
      "chargeoff_within_12_mths\n",
      "delinq_amnt\n",
      "mo_sin_old_il_acct\n",
      "mo_sin_old_rev_tl_op\n",
      "mo_sin_rcnt_rev_tl_op\n",
      "mo_sin_rcnt_tl\n",
      "mort_acc\n",
      "mths_since_recent_bc\n",
      "mths_since_recent_inq\n",
      "num_accts_ever_120_pd\n",
      "num_actv_bc_tl\n",
      "num_actv_rev_tl\n",
      "num_bc_sats\n",
      "num_bc_tl\n",
      "num_il_tl\n",
      "num_op_rev_tl\n",
      "num_rev_accts\n",
      "num_rev_tl_bal_gt_0\n",
      "num_sats\n",
      "num_tl_120dpd_2m\n",
      "num_tl_30dpd\n",
      "num_tl_90g_dpd_24m\n",
      "num_tl_op_past_12m\n",
      "pct_tl_nvr_dlq\n",
      "percent_bc_gt_75\n",
      "pub_rec_bankruptcies\n",
      "tax_liens\n",
      "tot_hi_cred_lim\n",
      "total_bal_ex_mort\n",
      "total_bc_limit\n",
      "total_il_high_credit_limit\n",
      "hardship_flag\n",
      "debt_settlement_flag\n"
     ]
    }
   ],
   "source": [
    "# add missing dummy variables to testing set\n",
    "for column in train_X.columns:\n",
    "    print(column)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION\n",
    "I predict that the Logistic Regression model will be more accurate than the Random Forest Classifier model because the Random Forest Classifier seems too scattered and the data has not been scaled yet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7359605911330049\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalle\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the unscaled data and print the model score\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_X, train_y)\n",
    "\n",
    "print(f'Training Data Score: {classifier.score(train_X, train_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 1.0\n",
      "Testing Score: 0.6452573373032752\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(train_X, train_y)\n",
    "print(f'Training Score: {clf.score(train_X, train_y)}')\n",
    "print(f'Testing Score: {clf.score(test_X, test_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler().fit(train_X)\n",
    "train_X_scaled = scaler.transform(train_X)\n",
    "test_X_scaled = scaler.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PREDICTION\n",
    "I predict that the Logistic Regression model will still be more accurate than the Random Forest Classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 0.7553366174055829\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nalle\\anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# Train the Logistic Regression model on the scaled data and print the model score\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(train_X_scaled, train_y)\n",
    "\n",
    "print(f'Training Data Score: {classifier.score(train_X_scaled, train_y)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.48801313628899834\n",
      "Testing Score: 0.4666099532113994\n"
     ]
    }
   ],
   "source": [
    "# Train a Random Forest Classifier model on the scaled data and print the model score\n",
    "clf = RandomForestClassifier(random_state=1, n_estimators=500).fit(train_X_scaled, train_y)\n",
    "print(f'Training Score: {clf.score(train_X, train_y)}')\n",
    "print(f'Testing Score: {clf.score(test_X, test_y)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONCLUSION\n",
    "My predictions were accurate, both times the Logistic Regression model had higher scores than the Random Forest Classifier model. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
